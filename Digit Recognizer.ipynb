{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idnetify digits from handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check cuda availability\n",
    "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training set and validation set\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "split = len(train)*4//5\n",
    "X_train = train[:split,1:]\n",
    "y_train = train[:split,0]\n",
    "X_val = train[split:,1:]\n",
    "y_val = train[split:,0]\n",
    "\n",
    "# Transform numpy array to torch tensor\n",
    "X_train = torch.tensor(X_train.astype(float))\n",
    "y_train = torch.tensor(y_train.astype(float))\n",
    "X_val = torch.tensor(X_val.astype(float))\n",
    "y_val = torch.tensor(y_val.astype(float))\n",
    "test = torch.tensor(test.astype(float))\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.view(-1, 28, 28).unsqueeze(1)\n",
    "X_val = X_val.view(-1, 28, 28).unsqueeze(1)\n",
    "test = test.view(-1, 28, 28).unsqueeze(1)\n",
    "\n",
    "# Normalize data\n",
    "X_train = (X_train-X_train.mean())/X_train.std()\n",
    "X_val = (X_val-X_val.mean())/X_val.std()\n",
    "test = (test - test.mean())/test.std()\n",
    "\n",
    "# Cast data to other data types\n",
    "X_train = X_train.float()\n",
    "y_train = y_train.long()\n",
    "X_val = X_val.float()\n",
    "y_val = y_val.long()\n",
    "test = test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network subclass\n",
    "# After parameter tuning, set number of channels 3.\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # c: number of channels\n",
    "    # r: ratio to define dimension of output in hidden layers\n",
    "    def __init__(self, c=12):\n",
    "        super().__init__()\n",
    "        self.c = c\n",
    "        self.conv1 = nn.Conv2d(1, c, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(c, c, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(7*7*(c), 7*7*(c))\n",
    "        self.fc2 = nn.Linear(7*7*(c), 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 7*7*(self.c))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, optimizer, model, loss_f, train_loader):\n",
    "    for epoch in tqdm_notebook(range(epochs), position=0, leave=True):\n",
    "        loss_train = 0.0\n",
    "        for x, y in train_loader:\n",
    "            out = model(x.to(device=device))\n",
    "            loss = loss_f(out, y.to(device=device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if epoch % 50 == 0 or epoch == epochs - 1:\n",
    "            print(epoch, loss_train/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=150.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b713ab7282b449a6834bcd57fccf57e6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.5303895631805062\n",
      "50 5.021021287632266e-06\n",
      "100 1.317615890172874e-06\n",
      "149 5.008171362064218e-07\n",
      "\n",
      "0.9902380952380953\n"
     ]
    }
   ],
   "source": [
    "# Create data set variable\n",
    "ds = TensorDataset(X_train, y_train)\n",
    "dl = DataLoader(ds, batch_size=1050, shuffle=True)\n",
    "\n",
    "# Training model\n",
    "# After parameter tuning, set learning rate 0.006, number of epochs 150\n",
    "model = Net()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.006)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "training_loop(150, optim, model.to(device), loss, dl)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X_val)):\n",
    "    ans = model(X_val[i].unsqueeze(0).to(device))\n",
    "    if torch.argmax(ans) == y_val[i]:\n",
    "        correct += 1\n",
    "print(correct/len(X_val))"
   ]
  },
  {
   "source": [
    "## Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "ind = []\n",
    "for i in range(len(test)):\n",
    "    ind.append(i+1)\n",
    "    ans = model(test[i].unsqueeze(0).to(device))\n",
    "    predict.append(torch.argmax(ans).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"ImageId\": ind, \"Label\": predict})\n",
    "result.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}